# How to aggregate.
aggregation_type=svm

# If type is 'weights', an array of weights applied to each metric, then a final constant to add.
# If type is 'script', the path to the script.
aggregation_value=svm.py

# Whether the metric scores should be centered and reduced in [0,1].
center_metrics=true

# true if the correctness is in the input file; else represents a threshold: 
# problems with scores superior than the threshold will be considered as correct.
correctness=0.0005

# The part of sequences used as test set.
cross_validation=0.1

# false if expected knowledge and computed knowledge should be compared as is.
# Else, expected knowledge is binary; and computed knowledge will be compared to it using this threshold. 
expected_binary=false

# The relative path to the file containing input data.
input_file=results.csv

# The list of thresholds to apply to the metrics. Required to apply Knowledge Tracing on each metric.
# If a threshold starts with '<', then the score needs to be inferior to the threshold to be valid.  
metric_threshold=[0.75,0.041377,0.232558,0.056429,<0.00001,0.021058,0.209524,0.968481,0.953462,0.019283,<0.095587,0.337819,0.156189,0.060403,0.01,<0.00001]

# The list of metrics.
# rating	reviewTextLength	summaryLength	reviewTextLengthSpellingErrorRatio	summarySpellingErrorRatio	reviewTextFOG	summaryFOG	reviewTextFK	summaryFK	reviewTextARI	summaryARI	reviewTextCLI	summaryCLI	polarityReviewText	polaritySummary	deviation
metrics=[]

# The path to the file to export the computed parameters.
output_params=output-params-10-svm.csv

# The path to the file to export the local KT parameters per metric.
output_local_KT=output-local-kt.csv

# The path to the file to export the knowledge found for each problem.
output_sequences=output-sequences-10-svm.csv

# The path to the file to export the knowledge found for each metric.
output_metrics=null

# The path to the file to export the data to make user graphs.
output_user_graphs=output-usergraphs.csv

# How to handle the input scores. 'compute' to use the metrics to calculate the score; 'reduce' to reduce and center the input scores; or 'nothing' to use the input scores as is.
scores=reduce

# If 'false', only the last problem of each sequence will be used for RMSE.
# If 'true', each problem from the closest to expected to the end will be used.
smooth_rmse=true

# false if no split. Else, represents the maximum number of consecutive problems that can be considered as noise.
split=false
