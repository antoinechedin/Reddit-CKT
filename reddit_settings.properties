# How to aggregate.
aggregation_type=weights

# If type is 'weights', an array of weights applied to each metric, then a final constant to add.
# If type is 'script', the path to the script.
aggregation_value=[0.01363,0.49828,0.29803,-0.25605,-0.67065,152.26198,-34.1695,-0.44757,0.06096,-0.86812,-0.24093,-20.18582,7.23408]

# Whether the metric scores should be centered and reduced in [0,1].
center_metrics=true

# true if the correctness is in the input file; else represents a threshold: 
# problems with scores superior than the threshold will be considered as correct.
correctness=10

# The part of sequences used as test set.
cross_validation=0.1

# false if expected knowledge and computed knowledge should be compared as is.
# Else, expected knowledge is binary; and computed knowledge will be compared to it using this threshold. 
expected_binary=false

# The relative path to the file containing input data.
input_file=results.csv

# False if no knowledge tracing on the metrics. (metrics are only used to compute the score).
kt_on_metrics=false

# The list of thresholds to apply to the metrics. Required to apply Knowledge Tracing on each metric.
# If a threshold starts with '<', then the score needs to be inferior to the threshold to be valid.  
metric_threshold=[]

# The list of metrics.
# rating	reviewTextLength	summaryLength	reviewTextLengthSpellingErrorRatio	summarySpellingErrorRatio	reviewTextFOG	summaryFOG	reviewTextFK	summaryFK	reviewTextARI	summaryARI	reviewTextCLI	summaryCLI	polarityReviewText	polaritySummary	deviation
metrics=[selftextLength,selftextARI,titleARI,selftextSpellingError,titleSpellingError,selftextSpellingErrorRatio,titleSpellingErrorRatio,selftextFOG,selftextFK,selftextCLI,titleCLI,polaritySelftext]

# The path to the file to export the computed parameters.
output_params=output-params-10-svm.csv

# The path to the file to export the local KT parameters per metric.
output_local_KT=output-local-kt.csv

# The path to the file to export the knowledge found for each problem.
output_sequences=output-sequences-10-svm.csv

# The path to the file to export the knowledge found for each metric.
output_metrics=null

# The path to the file to export the data to make user graphs.
output_user_graphs=output-usergraphs.csv

# How to handle the input scores. 'compute' to use the metrics to calculate the score; 'reduce' to reduce and center the input scores; or 'nothing' to use the input scores as is.
scores=compute

# If 'false', only the last problem of each sequence will be used for RMSE.
# If 'true', each problem from the closest to expected to the end will be used.
smooth_rmse=true

# false if no split. Else, represents the maximum number of consecutive problems that can be considered as noise.
split=false
