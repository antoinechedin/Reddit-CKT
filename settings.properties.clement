# How to aggregate metrics after running KT on each metric.
aggregation_type=svm

# If type is 'weights', an array of weights applied to each metric, then a final constant to add. [0.5,1,2]
# If type is 'script', the path to the javascript file.
# If type is 'svm', the path to the SVM python script file.
aggregation_value=svm.py

# Whether the metric scores should be centered and reduced in [0,1].
center_metrics=false

# 'true' if the correctness is in the input file; else represents a threshold: 
# Problems with scores greater than the threshold will be considered as correct.
correctness=0.9

# The part of sequences used as test set.
cross_validation=0.1

# 'false' if expected knowledge and computed knowledge should be compared as is.
# Else, expected knowledge is binary; and computed knowledge will be compared to it using this threshold. 
expected_binary=0.6

# The relative (to the jar) path to the file containing input data.
input_file=reviews-normalized-11.csv

# The list of thresholds to apply to the metrics. Required to apply Knowledge Tracing on each metric.
# If a threshold starts with '<', then the score needs to be inferior to the threshold to be valid.  
metric_threshold=[0.75,0.041377,0.232558,<0.060713,0.968481,0.337819,0.156189,0.083270,<0.0001]

# The list of metrics.
metrics=[rating,reviewTextLength,summaryLength,spellingErrRatio,reviewTextFK,reviewTextCLI,summaryCLI,polarity,deviation]

# The path to the file to export the computed parameters.
output_params=output-params-11.csv

# The path to the file to export the knowledge found for each problem.
output_sequences=output-sequences-11.csv

# The path to the file to export the knowledge found for each problem and each metric.
output_metrics=null

# How to handle the input scores. 
# 'compute' to use the metrics to calculate the score; 
# 'reduce' to reduce and center the input scores; 
# 'nothing' to use the input scores.
scores=nothing

# If 'false', only the last problem of each sequence will be used for RMSE.
# If 'true', each problem from the closest to expected to the end will be used.
smooth_rmse=true

# 'false' if no split. Else, represents the maximum number of consecutive problems that can be considered as noise. (for exploratory analysis)
split=false
